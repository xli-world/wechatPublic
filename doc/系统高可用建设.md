### 如何建设高可用的系统

#### 引言

随着业务的发展和公司内部的推广，之前主导开发的一个系统逐渐成为了公司内部较重要的服务，老大们越来越在意这个系统的可用性。因此，今年大部分时间都花在了服务可用性建设上了，谨以此篇讲述下这半年的经验，主要包括两个问题：

1. 如何建设一个高可用的系统；
2. 如何证明自己的系统高可用。

#### 可用性SLA

SLA，全称Service Level Agrement，服务级别协议，是在一定开销下为保障服务的性能和可用性，服务提供商与用户间定义的一种双方认可的协定，也就是我们常说的几个9。

业界高可用的标准是按照系统宕机时间来衡量的：

| 系统可用性%    | 宕机时间/年 | 宕机时间/月 | 宕机时间/周 | 宕机时间/天 |
| :------------- | :---------- | :---------- | :---------- | :---------- |
| 90% (1个9)     | 36.5 天     | 72 小时     | 16.8 小时   | 2.4 小时    |
| 99% (2个9)     | 3.65 天     | 7.20 小时   | 1.68 小时   | 14.4 分     |
| 99.9% (3个9)   | 8.76 小时   | 43.8 分     | 10.1 分钟   | 1.44 分     |
| 99.99% (4个9)  | 52.56 分    | 4.38 分     | 1.01 分钟   | 8.66 秒     |
| 99.999% (5个9) | 5.26 分     | 25.9 秒     | 6.05 秒     | 0.87 秒     |

要达到99.999%的可用性，一年只能有5分半钟的服务不可用，这是很难做到的；就算是3个9的可用性，一个月的宕机时间也只有40多分钟，如果设计或编码不认真，运维团队又缺乏高效的自动化故障处理工具，想要达到3个9也是比较困难的。

业界系统可靠性还有两个比较常用的关键指标：

- 平均无故障时间(MTBF，Mean Time Between Failure)：系统平均正常运行多长时间，才发生一次故障。
- 平均修复时间(MTTR，Mean Time To Repair)：系统由故障状态转为工作状态时修理时间的平均值。

提升服务可用性也主要是从这两个指标下手：

1. 减少故障频率，提高MTBF；
2. 加快故障恢复速度，降低MTTR；
3. 出现故障时降低故障的影响力，即尽量缩小故障范围。

#### 减少故障频率

减少故障频率主要从以下几点考虑：

1. 避免自己的处理逻辑有误；
2. 在依赖的组件或服务出问题时，减少影响范围或者设置好备选方案；
3. 对输入做好限制，避免被调用方打挂。

##### 避免处理逻辑有误

部署层面，需要考虑同城双活、两地三中心这样的方案，避免某个区域出现异常之后导致整个服务不可用。

开发层面主要遵循以下几点：

1. 开发、测试、上线流程规范化，降低人为因素带来的影响；
2. 用好CICD、devops，做好持续集成持续测试；
3. 系统部署时需设置好冗余，避免突发事件导致服务调用量突增；

##### 降低依赖崩溃的影响

1. 依赖项进行梳理，哪些是强依赖，哪些是弱依赖，哪些依赖有备选方案；
2. 确认是否可以通过消息队列等方式减少依赖项；
3. 对于所有的依赖项都需设置合理的超时和重试机制；
4. 对于弱依赖项，可以设置熔断机制，向上提供有损服务，保证业务柔性可用；
5. 对于强依赖项，也可根据实际情况设置熔断机制，必要情况下，可选择较友好的方式告知调用方服务不可用。

##### 做好输入限制

输入限制包括以下两点：

1. 完善的输入校验，避免输入恶意数据，引发未知bug
2. 对调用方做好限流，避免因DDOS攻击、突发事件或者调用方的bug（请求放大、错误的失败重试等）导致系统崩溃。业界用的较多的算法有令牌桶、漏桶、计数器，主流的语言一般都有开源实现。

#### 加快故障恢复速度

加快故障恢复速度取决于三点：快速发现、快速定位、快速解决。

##### 快速发现故障

快速发现故障依赖于完善的监控体系和例行的压测、故障演练。

常用的机器类监控指标一般有CPU、内存、磁盘IO、网络IO等，常用的服务类监控指标一般有调用量、平均处理时间、最大处理时间、成功次数、失败次数、GC次数、goroutine数量等。

##### 快速定位故障

故障定位依赖于完整靠谱的故障数据，一般包括服务日志、监控指标，有时候还可能用到机器系统日志。设计良好的日志规约及通用的监控指标至关重要。

##### 快速解决故障

快速解决故障依赖于故障的快速发现和快速定位，因此可以做一个系统集成上述监控信息和日志信息，相应的告警信息里面也需带上详情链接，方便开发人员高效定位。

可以事先收集一些通用的故障，并开发相应的自动化工具帮助开发人员快速解决问题。比方说，如果故障是由于调用量大增导致的，可以开发个一键重启并扩容的功能，快速提高系统处理能力。

#### 降低故障影响力

降低故障影响力的主要方式是将系统或资源分割开，在系统发生故障时能限定影响范围。

##### 服务器物理隔离

隔离原则如下：

- 内外有别：内部系统与对外开放平台区分对待。
- 内部隔离：从上游到下游按通道或调用方重要程度从物理服务器上进行隔离，低流量服务合并。

##### 资源隔离

资源隔离包括系统自身资源（CPU、内存等）及共享资源（DB等）：

1. 处理请求时，可通过goroutine的方式进行处理，实现线程级别的隔离。对于每个请求还需设置合理的超时时间，避免goroutine一直占用资源，造成资源泄露。
2. 对于共享资源，需要做好限流限制，避免耗尽资源。

#### 证明系统高可用性

上述所有的操作其实就是对你系统高可用性的理论证明，至于实际证明，可通过例行的故障演练和线上的实际情况来证明。

#### 总结

本文更多的是讲一些道的层面的东西，对于术的层面，不同的业务不同的开发环境都有所区别，得具体问题具体分析。当然，道的层面理解了，术方面更多的只是细节的把握和工具、方法的选型，可以根据实际情况慢慢优化，毕竟高可用是个跟随系统迭代持续构建的过程，无法做到一劳永逸。